{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "잡케어추천알고리즘_TabNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMk8Q1DEnWM6Va3jMm9w5mF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doo52oh/Dacon/blob/main/%EC%9E%A1%EC%BC%80%EC%96%B4%EC%B6%94%EC%B2%9C/%EC%9E%A1%EC%BC%80%EC%96%B4%EC%B6%94%EC%B2%9C%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_TabNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwTv2Q1feVa3",
        "outputId": "4b84723d-4545-4308-c03e-334ab5c398ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet==3.1.1\n",
            "  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (1.0.2)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (4.62.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet==3.1.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet==3.1.1) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet==3.1.1) (3.10.0.2)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet==3.1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import Dict\n",
        "from datetime import datetime\n",
        "## preprocessing\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "## modeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from pytorch_tabnet.tab_model  import TabNetClassifier \n",
        "from pytorch_tabnet.metrics import Metric\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wia8aS7PfBms",
        "outputId": "2618daca-c1fa-4f16-8836-e3c401c3b7f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Dacon/JobCare/data/\"\n",
        "SUBMIT_PATH = \"/content/drive/MyDrive/Dacon/JobCare/submit/\"\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "qTB8Tci7fCV2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(f'{DATA_PATH}train.csv')\n",
        "test_data = pd.read_csv(f'{DATA_PATH}test.csv')\n",
        "\n",
        "d_code = pd.read_csv(f'{DATA_PATH}속성_D_코드.csv', index_col=0).T.to_dict()\n",
        "h_code = pd.read_csv(f'{DATA_PATH}속성_H_코드.csv', index_col=0).T.to_dict()\n",
        "l_code = pd.read_csv(f'{DATA_PATH}속성_L_코드.csv', index_col=0).T.to_dict()\n",
        "\n",
        "print(\"train_data.shape: \", train_data.shape)\n",
        "print(\"test_data.shape: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbl7Gv87fIiq",
        "outputId": "3fe3fba5-a687-41ce-fd1f-79ed74277fbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 35)\n",
            "test_data.shape:  (46404, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_code(\n",
        "    df: pd.DataFrame,\n",
        "    d_code: Dict[int, Dict[str, int]], \n",
        "    h_code: Dict[int, Dict[str, int]], \n",
        "    l_code: Dict[int, Dict[str, int]],\n",
        ") -> pd.DataFrame:\n",
        "    \n",
        "    # Copy input data\n",
        "    df = df.copy()   \n",
        "\n",
        "    # D Code\n",
        "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    # H Code\n",
        "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    \n",
        "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    \n",
        "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    # L Code\n",
        "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
        "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
        "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
        "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
        "    \n",
        "    return df\n",
        "\n",
        "train_data = add_code(train_data, d_code, h_code, l_code)\n",
        "test_data = add_code(test_data, d_code, h_code, l_code)\n",
        "print(\"train_data.shape: \", train_data.shape)\n",
        "print(\"test_data.shape: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4XNO9D-fJzr",
        "outputId": "439b851d-85a2-474e-9156-41795b333777"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 63)\n",
            "test_data.shape:  (46404, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_contents_open_dt(data):\n",
        "    data['contents_open_dt'] = data['contents_open_dt'].astype('str')\n",
        "    DATE = data['contents_open_dt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
        "    \n",
        "    DATE = pd.DataFrame(DATE)\n",
        "    DATE = DATE.rename(columns = {'contents_open_dt': 'date'})\n",
        "    \n",
        "    DATE['Y'] = DATE['date'].apply(lambda x: x.timetuple()[0])\n",
        "    DATE['M'] = DATE['date'].apply(lambda x: x.timetuple()[1])\n",
        "    DATE['D'] = DATE['date'].apply(lambda x: x.timetuple()[2])\n",
        "    DATE['id'] = data['id']\n",
        "    \n",
        "    data = data.merge(DATE, on = 'id', how = 'left')\n",
        "    data = data.drop(columns = ['date', 'contents_open_dt'])\n",
        "    return data\n",
        "\n",
        "train_data = preprocessing_contents_open_dt(train_data)\n",
        "test_data = preprocessing_contents_open_dt(test_data)\n",
        "\n",
        "# 안전하게 확인하고 넘어 갑시다. \n",
        "train_data_labels = train_data['target']\n",
        "train_data, test_data = train_data.align(test_data, join = 'inner', axis = 1)\n",
        "train_data['target'] = train_data_labels\n",
        "print(\"train_data.shape: \", train_data.shape)\n",
        "print(\"test_data.shape: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWYiFWQtfL46",
        "outputId": "49bee0c3-9cbd-42da-bf15-be8a4533b18a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 65)\n",
            "test_data.shape:  (46404, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_data = train_data.copy()\n",
        "job_data_test = test_data.copy()"
      ],
      "metadata": {
        "id": "si9s72C0fNN_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = ['id', 'person_rn', 'contents_rn', 'Y', 'M', 'D','person_prefer_f','person_prefer_g']\n",
        "\n",
        "job_df = job_data.drop(drop_cols, axis=1)\n",
        "job_test_df = job_data_test.drop(drop_cols, axis=1)"
      ],
      "metadata": {
        "id": "2A0hIdCtfPK3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M7a7qZtfVoK",
        "outputId": "456d7f3f-3072-4810-de20-0555bcdd019b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 501951 entries, 0 to 501950\n",
            "Data columns (total 58 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   d_l_match_yn            501951 non-null  bool  \n",
            " 1   d_m_match_yn            501951 non-null  bool  \n",
            " 2   d_s_match_yn            501951 non-null  bool  \n",
            " 3   h_l_match_yn            501951 non-null  bool  \n",
            " 4   h_m_match_yn            501951 non-null  bool  \n",
            " 5   h_s_match_yn            501951 non-null  bool  \n",
            " 6   person_attribute_a      501951 non-null  int64 \n",
            " 7   person_attribute_a_1    501951 non-null  int64 \n",
            " 8   person_attribute_b      501951 non-null  int64 \n",
            " 9   person_prefer_c         501951 non-null  int64 \n",
            " 10  person_prefer_d_1       501951 non-null  int64 \n",
            " 11  person_prefer_d_2       501951 non-null  int64 \n",
            " 12  person_prefer_d_3       501951 non-null  int64 \n",
            " 13  person_prefer_e         501951 non-null  int64 \n",
            " 14  person_prefer_h_1       501951 non-null  int64 \n",
            " 15  person_prefer_h_2       501951 non-null  int64 \n",
            " 16  person_prefer_h_3       501951 non-null  int64 \n",
            " 17  contents_attribute_i    501951 non-null  int64 \n",
            " 18  contents_attribute_a    501951 non-null  int64 \n",
            " 19  contents_attribute_j_1  501951 non-null  int64 \n",
            " 20  contents_attribute_j    501951 non-null  int64 \n",
            " 21  contents_attribute_c    501951 non-null  int64 \n",
            " 22  contents_attribute_k    501951 non-null  int64 \n",
            " 23  contents_attribute_l    501951 non-null  int64 \n",
            " 24  contents_attribute_d    501951 non-null  int64 \n",
            " 25  contents_attribute_m    501951 non-null  int64 \n",
            " 26  contents_attribute_e    501951 non-null  int64 \n",
            " 27  contents_attribute_h    501951 non-null  int64 \n",
            " 28  person_prefer_d_1_n     501951 non-null  int64 \n",
            " 29  person_prefer_d_1_s     501951 non-null  int64 \n",
            " 30  person_prefer_d_1_m     501951 non-null  int64 \n",
            " 31  person_prefer_d_1_l     501951 non-null  int64 \n",
            " 32  person_prefer_d_2_n     501951 non-null  int64 \n",
            " 33  person_prefer_d_2_s     501951 non-null  int64 \n",
            " 34  person_prefer_d_2_m     501951 non-null  int64 \n",
            " 35  person_prefer_d_2_l     501951 non-null  int64 \n",
            " 36  person_prefer_d_3_n     501951 non-null  int64 \n",
            " 37  person_prefer_d_3_s     501951 non-null  int64 \n",
            " 38  person_prefer_d_3_m     501951 non-null  int64 \n",
            " 39  person_prefer_d_3_l     501951 non-null  int64 \n",
            " 40  contents_attribute_d_n  501951 non-null  int64 \n",
            " 41  contents_attribute_d_s  501951 non-null  int64 \n",
            " 42  contents_attribute_d_m  501951 non-null  int64 \n",
            " 43  contents_attribute_d_l  501951 non-null  int64 \n",
            " 44  person_prefer_h_1_l     501951 non-null  int64 \n",
            " 45  person_prefer_h_1_m     501951 non-null  int64 \n",
            " 46  person_prefer_h_2_l     501951 non-null  int64 \n",
            " 47  person_prefer_h_2_m     501951 non-null  int64 \n",
            " 48  person_prefer_h_3_l     501951 non-null  int64 \n",
            " 49  person_prefer_h_3_m     501951 non-null  int64 \n",
            " 50  contents_attribute_h_l  501951 non-null  int64 \n",
            " 51  contents_attribute_h_m  501951 non-null  int64 \n",
            " 52  contents_attribute_l_n  501951 non-null  int64 \n",
            " 53  contents_attribute_l_s  501951 non-null  int64 \n",
            " 54  contents_attribute_l_m  501951 non-null  int64 \n",
            " 55  contents_attribute_l_l  501951 non-null  int64 \n",
            " 56  target                  501951 non-null  int64 \n",
            " 57  Set                     501951 non-null  object\n",
            "dtypes: bool(6), int64(51), object(1)\n",
            "memory usage: 205.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "if \"Set\" not in job_df.columns:\n",
        "    job_df[\"Set\"] = np.random.choice([\"train\", \"valid\"], p =[.8, .2], size=(job_df.shape[0],))\n",
        "\n",
        "train_indices = job_df[job_df.Set==\"train\"].index\n",
        "valid_indices = job_df[job_df.Set==\"valid\"].index\n"
      ],
      "metadata": {
        "id": "GJkvRvS5fXSA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = job_df.loc[job_df.Set == 'train'].drop(\"Set\", axis=1)\n",
        "valid = job_df.loc[job_df.Set == 'valid'].drop(\"Set\", axis=1)\n",
        "test = job_test_df"
      ],
      "metadata": {
        "id": "m8t0NbZE3SpQ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, valid.shape, test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aixLt7_F3fCA",
        "outputId": "9d41af46-33dd-4fe9-84cc-7480cad276b7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((401574, 57), (100377, 57), (46404, 56))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_idxs = []\n",
        "cat_dims = []\n",
        "for idx, col in enumerate(train.columns):\n",
        "  print(idx,col)\n",
        "  if 'match' not in col and col!='target': \n",
        "        le = LabelEncoder()\n",
        "        le.fit(train[col].values)\n",
        "        le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "        train[col] = train[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
        "        valid[col] = valid[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
        "        test[col] = test[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
        "        cat_idxs.append(idx)\n",
        "        cat_dims.append(len(le_dict)+1)"
      ],
      "metadata": {
        "id": "tHizaQqEfcOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd10dcbe-9ebe-4669-8270-9d3250508aa5"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 d_l_match_yn\n",
            "1 d_m_match_yn\n",
            "2 d_s_match_yn\n",
            "3 h_l_match_yn\n",
            "4 h_m_match_yn\n",
            "5 h_s_match_yn\n",
            "6 person_attribute_a\n",
            "7 person_attribute_a_1\n",
            "8 person_attribute_b\n",
            "9 person_prefer_c\n",
            "10 person_prefer_d_1\n",
            "11 person_prefer_d_2\n",
            "12 person_prefer_d_3\n",
            "13 person_prefer_e\n",
            "14 person_prefer_h_1\n",
            "15 person_prefer_h_2\n",
            "16 person_prefer_h_3\n",
            "17 contents_attribute_i\n",
            "18 contents_attribute_a\n",
            "19 contents_attribute_j_1\n",
            "20 contents_attribute_j\n",
            "21 contents_attribute_c\n",
            "22 contents_attribute_k\n",
            "23 contents_attribute_l\n",
            "24 contents_attribute_d\n",
            "25 contents_attribute_m\n",
            "26 contents_attribute_e\n",
            "27 contents_attribute_h\n",
            "28 person_prefer_d_1_n\n",
            "29 person_prefer_d_1_s\n",
            "30 person_prefer_d_1_m\n",
            "31 person_prefer_d_1_l\n",
            "32 person_prefer_d_2_n\n",
            "33 person_prefer_d_2_s\n",
            "34 person_prefer_d_2_m\n",
            "35 person_prefer_d_2_l\n",
            "36 person_prefer_d_3_n\n",
            "37 person_prefer_d_3_s\n",
            "38 person_prefer_d_3_m\n",
            "39 person_prefer_d_3_l\n",
            "40 contents_attribute_d_n\n",
            "41 contents_attribute_d_s\n",
            "42 contents_attribute_d_m\n",
            "43 contents_attribute_d_l\n",
            "44 person_prefer_h_1_l\n",
            "45 person_prefer_h_1_m\n",
            "46 person_prefer_h_2_l\n",
            "47 person_prefer_h_2_m\n",
            "48 person_prefer_h_3_l\n",
            "49 person_prefer_h_3_m\n",
            "50 contents_attribute_h_l\n",
            "51 contents_attribute_h_m\n",
            "52 contents_attribute_l_n\n",
            "53 contents_attribute_l_s\n",
            "54 contents_attribute_l_m\n",
            "55 contents_attribute_l_l\n",
            "56 target\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.drop('target',axis=1).values\n",
        "y_train = train['target'].values\n",
        "X_val = val.drop('target',axis=1).values\n",
        "y_val = val['target'].values\n",
        "X_test = test.values\n",
        "eval_set = (X_val,y_val)"
      ],
      "metadata": {
        "id": "A4-elMjF3lA0"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3_9Q0wkvDWs",
        "outputId": "a9ac2bf9-2b49-43fd-95d7-666d8cdebb07"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((401574, 56), (401574,), (501951, 56), (501951,), (46404, 56))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TabNet"
      ],
      "metadata": {
        "id": "ZKQUDR5XfhOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier(cat_idxs=cat_idxs,\n",
        "                       cat_dims=cat_dims,\n",
        "                       cat_emb_dim=3,\n",
        "                       optimizer_fn=torch.optim.AdamW, # Any optimizer works here\n",
        "                       mask_type='entmax', # \"sparsemax\",\n",
        "                      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fOZw3fnffKT",
        "outputId": "5eb56815-cd60-40b6-c932-2216373f2702"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device used : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    eval_name=['train', 'val'],\n",
        "    eval_metric=['logloss','auc'],\n",
        "    max_epochs=100 , patience=2,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=256,\n",
        "    num_workers=1,\n",
        "    drop_last=False,\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "Yw_A2Vzv1dYB",
        "outputId": "801b3497-4cb0-4716-ff48-b6d631b969e2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-9dd7a60ab897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvirtual_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m ) \n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# Apply predict epoch to all eval sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;31m# Call method on_epoch_end for all callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36m_predict_epoch\u001b[0;34m(self, name, loader)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# Main loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mlist_y_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mlist_y_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36m_predict_batch\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# compute model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m                 cols.append(\n\u001b[0;32m--> 849\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_feat_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_init_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m                 )\n\u001b[1;32m    851\u001b[0m                 \u001b[0mcat_feat_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WE3D7seV2ceX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}