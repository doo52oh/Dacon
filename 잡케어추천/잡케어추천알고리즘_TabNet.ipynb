{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "잡케어추천알고리즘_TabNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOqsuMxbSALgqFCAPzvnvl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doo52oh/Dacon/blob/main/%EC%9E%A1%EC%BC%80%EC%96%B4%EC%B6%94%EC%B2%9C/%EC%9E%A1%EC%BC%80%EC%96%B4%EC%B6%94%EC%B2%9C%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_TabNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwTv2Q1feVa3",
        "outputId": "bc9e6b59-9a64-4448-8a5b-bfd421c6f3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-tabnet==3.1.1 in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (1.0.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (4.62.3)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet==3.1.1) (1.10.0+cu111)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet==3.1.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet==3.1.1) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet==3.1.1) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet==3.1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import Dict\n",
        "from datetime import datetime\n",
        "## preprocessing\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "## modeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from pytorch_tabnet.tab_model  import TabNetClassifier \n",
        "from pytorch_tabnet.metrics import Metric\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wia8aS7PfBms",
        "outputId": "e356ebee-77a8-4c42-b2ea-9b9b5555a927"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Dacon/JobCare/data/\"\n",
        "SUBMIT_PATH = \"/content/drive/MyDrive/Dacon/JobCare/submit/\"\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "qTB8Tci7fCV2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(f'{DATA_PATH}train.csv')\n",
        "test_data = pd.read_csv(f'{DATA_PATH}test.csv')\n",
        "\n",
        "d_code = pd.read_csv(f'{DATA_PATH}속성_D_코드.csv', index_col=0).T.to_dict()\n",
        "h_code = pd.read_csv(f'{DATA_PATH}속성_H_코드.csv', index_col=0).T.to_dict()\n",
        "l_code = pd.read_csv(f'{DATA_PATH}속성_L_코드.csv', index_col=0).T.to_dict()\n",
        "\n",
        "print(\"train_data.shape: \", train_data.shape)\n",
        "print(\"test_data.shape: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbl7Gv87fIiq",
        "outputId": "abd11a00-e2d5-4b3f-b08e-e7c60908306c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 35)\n",
            "test_data.shape:  (46404, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_code(\n",
        "    df: pd.DataFrame,\n",
        "    d_code: Dict[int, Dict[str, int]], \n",
        "    h_code: Dict[int, Dict[str, int]], \n",
        "    l_code: Dict[int, Dict[str, int]],\n",
        ") -> pd.DataFrame:\n",
        "    \n",
        "    # Copy input data\n",
        "    df = df.copy()   \n",
        "\n",
        "    # D Code\n",
        "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    # H Code\n",
        "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    \n",
        "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    \n",
        "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    # L Code\n",
        "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
        "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
        "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
        "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
        "    \n",
        "    return df\n",
        "\n",
        "train_data = add_code(train_data, d_code, h_code, l_code)\n",
        "test_data = add_code(test_data, d_code, h_code, l_code)\n",
        "print(\"train_data.shape: \", train_data.shape)\n",
        "print(\"test_data.shape: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4XNO9D-fJzr",
        "outputId": "c45cc574-26bf-4265-efa6-7cbcd80fdd86"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 63)\n",
            "test_data.shape:  (46404, 62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_contents_open_dt(data):\n",
        "    data['contents_open_dt'] = data['contents_open_dt'].astype('str')\n",
        "    DATE = data['contents_open_dt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
        "    \n",
        "    DATE = pd.DataFrame(DATE)\n",
        "    DATE = DATE.rename(columns = {'contents_open_dt': 'date'})\n",
        "    \n",
        "    DATE['Y'] = DATE['date'].apply(lambda x: x.timetuple()[0])\n",
        "    DATE['M'] = DATE['date'].apply(lambda x: x.timetuple()[1])\n",
        "    DATE['D'] = DATE['date'].apply(lambda x: x.timetuple()[2])\n",
        "    DATE['id'] = data['id']\n",
        "    \n",
        "    data = data.merge(DATE, on = 'id', how = 'left')\n",
        "    data = data.drop(columns = ['date', 'contents_open_dt'])\n",
        "    return data\n",
        "\n",
        "train_data = preprocessing_contents_open_dt(train_data)\n",
        "test_data = preprocessing_contents_open_dt(test_data)\n",
        "\n",
        "# 안전하게 확인하고 넘어 갑시다. \n",
        "train_data_labels = train_data['target']\n",
        "train_data, test_data = train_data.align(test_data, join = 'inner', axis = 1)\n",
        "train_data['target'] = train_data_labels\n",
        "print(\"train_data.shape: \", train_data.shape)\n",
        "print(\"test_data.shape: \", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWYiFWQtfL46",
        "outputId": "83208451-2dfa-465c-e033-6f19212dcf09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 65)\n",
            "test_data.shape:  (46404, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_data = train_data.copy()\n",
        "job_data_test = test_data.copy()"
      ],
      "metadata": {
        "id": "si9s72C0fNN_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cols = ['id', 'person_rn', 'contents_rn', 'Y', 'M', 'D','person_prefer_f','person_prefer_g']\n",
        "\n",
        "job_df = job_data.drop(drop_cols, axis=1)\n",
        "job_test_df = job_data_test.drop(drop_cols, axis=1)"
      ],
      "metadata": {
        "id": "2A0hIdCtfPK3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M7a7qZtfVoK",
        "outputId": "14bc2efb-ccce-4967-ba2a-abaabe8439a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 501951 entries, 0 to 501950\n",
            "Data columns (total 57 columns):\n",
            " #   Column                  Non-Null Count   Dtype\n",
            "---  ------                  --------------   -----\n",
            " 0   d_l_match_yn            501951 non-null  bool \n",
            " 1   d_m_match_yn            501951 non-null  bool \n",
            " 2   d_s_match_yn            501951 non-null  bool \n",
            " 3   h_l_match_yn            501951 non-null  bool \n",
            " 4   h_m_match_yn            501951 non-null  bool \n",
            " 5   h_s_match_yn            501951 non-null  bool \n",
            " 6   person_attribute_a      501951 non-null  int64\n",
            " 7   person_attribute_a_1    501951 non-null  int64\n",
            " 8   person_attribute_b      501951 non-null  int64\n",
            " 9   person_prefer_c         501951 non-null  int64\n",
            " 10  person_prefer_d_1       501951 non-null  int64\n",
            " 11  person_prefer_d_2       501951 non-null  int64\n",
            " 12  person_prefer_d_3       501951 non-null  int64\n",
            " 13  person_prefer_e         501951 non-null  int64\n",
            " 14  person_prefer_h_1       501951 non-null  int64\n",
            " 15  person_prefer_h_2       501951 non-null  int64\n",
            " 16  person_prefer_h_3       501951 non-null  int64\n",
            " 17  contents_attribute_i    501951 non-null  int64\n",
            " 18  contents_attribute_a    501951 non-null  int64\n",
            " 19  contents_attribute_j_1  501951 non-null  int64\n",
            " 20  contents_attribute_j    501951 non-null  int64\n",
            " 21  contents_attribute_c    501951 non-null  int64\n",
            " 22  contents_attribute_k    501951 non-null  int64\n",
            " 23  contents_attribute_l    501951 non-null  int64\n",
            " 24  contents_attribute_d    501951 non-null  int64\n",
            " 25  contents_attribute_m    501951 non-null  int64\n",
            " 26  contents_attribute_e    501951 non-null  int64\n",
            " 27  contents_attribute_h    501951 non-null  int64\n",
            " 28  person_prefer_d_1_n     501951 non-null  int64\n",
            " 29  person_prefer_d_1_s     501951 non-null  int64\n",
            " 30  person_prefer_d_1_m     501951 non-null  int64\n",
            " 31  person_prefer_d_1_l     501951 non-null  int64\n",
            " 32  person_prefer_d_2_n     501951 non-null  int64\n",
            " 33  person_prefer_d_2_s     501951 non-null  int64\n",
            " 34  person_prefer_d_2_m     501951 non-null  int64\n",
            " 35  person_prefer_d_2_l     501951 non-null  int64\n",
            " 36  person_prefer_d_3_n     501951 non-null  int64\n",
            " 37  person_prefer_d_3_s     501951 non-null  int64\n",
            " 38  person_prefer_d_3_m     501951 non-null  int64\n",
            " 39  person_prefer_d_3_l     501951 non-null  int64\n",
            " 40  contents_attribute_d_n  501951 non-null  int64\n",
            " 41  contents_attribute_d_s  501951 non-null  int64\n",
            " 42  contents_attribute_d_m  501951 non-null  int64\n",
            " 43  contents_attribute_d_l  501951 non-null  int64\n",
            " 44  person_prefer_h_1_l     501951 non-null  int64\n",
            " 45  person_prefer_h_1_m     501951 non-null  int64\n",
            " 46  person_prefer_h_2_l     501951 non-null  int64\n",
            " 47  person_prefer_h_2_m     501951 non-null  int64\n",
            " 48  person_prefer_h_3_l     501951 non-null  int64\n",
            " 49  person_prefer_h_3_m     501951 non-null  int64\n",
            " 50  contents_attribute_h_l  501951 non-null  int64\n",
            " 51  contents_attribute_h_m  501951 non-null  int64\n",
            " 52  contents_attribute_l_n  501951 non-null  int64\n",
            " 53  contents_attribute_l_s  501951 non-null  int64\n",
            " 54  contents_attribute_l_m  501951 non-null  int64\n",
            " 55  contents_attribute_l_l  501951 non-null  int64\n",
            " 56  target                  501951 non-null  int64\n",
            "dtypes: bool(6), int64(51)\n",
            "memory usage: 202.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "if \"Set\" not in job_df.columns:\n",
        "    job_df[\"Set\"] = np.random.choice([\"train\", \"valid\"], p =[.8, .2], size=(job_df.shape[0],))\n",
        "\n",
        "train_indices = job_df[job_df.Set==\"train\"].index\n",
        "valid_indices = job_df[job_df.Set==\"valid\"].index\n"
      ],
      "metadata": {
        "id": "GJkvRvS5fXSA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = job_df.loc[job_df.Set == 'train'].drop(\"Set\", axis=1)\n",
        "valid = job_df.loc[job_df.Set == 'valid'].drop(\"Set\", axis=1)\n",
        "test = job_test_df"
      ],
      "metadata": {
        "id": "m8t0NbZE3SpQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, valid.shape, test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aixLt7_F3fCA",
        "outputId": "e9c66951-1219-4ee0-db86-84c33c7e029a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((401574, 57), (100377, 57), (46404, 56))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_idxs = []\n",
        "cat_dims = []\n",
        "for idx, col in enumerate(train.columns):\n",
        "  print(idx,col)\n",
        "  if 'match' not in col and col!='target': \n",
        "        le = LabelEncoder()\n",
        "        le.fit(train[col].values)\n",
        "        le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "        train[col] = train[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
        "        valid[col] = valid[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
        "        test[col] = test[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
        "        cat_idxs.append(idx)\n",
        "        cat_dims.append(len(le_dict)+1)"
      ],
      "metadata": {
        "id": "tHizaQqEfcOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec4b861a-6d66-469d-a4b9-110196e518d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 d_l_match_yn\n",
            "1 d_m_match_yn\n",
            "2 d_s_match_yn\n",
            "3 h_l_match_yn\n",
            "4 h_m_match_yn\n",
            "5 h_s_match_yn\n",
            "6 person_attribute_a\n",
            "7 person_attribute_a_1\n",
            "8 person_attribute_b\n",
            "9 person_prefer_c\n",
            "10 person_prefer_d_1\n",
            "11 person_prefer_d_2\n",
            "12 person_prefer_d_3\n",
            "13 person_prefer_e\n",
            "14 person_prefer_h_1\n",
            "15 person_prefer_h_2\n",
            "16 person_prefer_h_3\n",
            "17 contents_attribute_i\n",
            "18 contents_attribute_a\n",
            "19 contents_attribute_j_1\n",
            "20 contents_attribute_j\n",
            "21 contents_attribute_c\n",
            "22 contents_attribute_k\n",
            "23 contents_attribute_l\n",
            "24 contents_attribute_d\n",
            "25 contents_attribute_m\n",
            "26 contents_attribute_e\n",
            "27 contents_attribute_h\n",
            "28 person_prefer_d_1_n\n",
            "29 person_prefer_d_1_s\n",
            "30 person_prefer_d_1_m\n",
            "31 person_prefer_d_1_l\n",
            "32 person_prefer_d_2_n\n",
            "33 person_prefer_d_2_s\n",
            "34 person_prefer_d_2_m\n",
            "35 person_prefer_d_2_l\n",
            "36 person_prefer_d_3_n\n",
            "37 person_prefer_d_3_s\n",
            "38 person_prefer_d_3_m\n",
            "39 person_prefer_d_3_l\n",
            "40 contents_attribute_d_n\n",
            "41 contents_attribute_d_s\n",
            "42 contents_attribute_d_m\n",
            "43 contents_attribute_d_l\n",
            "44 person_prefer_h_1_l\n",
            "45 person_prefer_h_1_m\n",
            "46 person_prefer_h_2_l\n",
            "47 person_prefer_h_2_m\n",
            "48 person_prefer_h_3_l\n",
            "49 person_prefer_h_3_m\n",
            "50 contents_attribute_h_l\n",
            "51 contents_attribute_h_m\n",
            "52 contents_attribute_l_n\n",
            "53 contents_attribute_l_s\n",
            "54 contents_attribute_l_m\n",
            "55 contents_attribute_l_l\n",
            "56 target\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.drop('target',axis=1).values\n",
        "y_train = train['target'].values\n",
        "X_val = valid.drop('target',axis=1).values\n",
        "y_val = valid['target'].values\n",
        "X_test = test.values\n",
        "# eval_set = (X_val,y_val)"
      ],
      "metadata": {
        "id": "A4-elMjF3lA0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3_9Q0wkvDWs",
        "outputId": "b6fea11c-a9f1-4ad9-a45c-b2f86a1edcd8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((401574, 56), (401574,), (100377, 56), (100377,), (46404, 56))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JhNNY8kxdMa",
        "outputId": "be0e48c7-9ae7-4c56-b9c2-600256e06c1d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[True, False, False, ..., 164, 40, 6],\n",
              "       [False, False, False, ..., 237, 60, 12],\n",
              "       [True, False, False, ..., 273, 67, 16],\n",
              "       ...,\n",
              "       [True, True, False, ..., 109, 27, 2],\n",
              "       [True, True, False, ..., 109, 27, 2],\n",
              "       [True, True, False, ..., 109, 27, 2]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM01MUF1xfdQ",
        "outputId": "8017853c-f853-4c4f-aba0-2a8f0bbb218a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[True, True, True, ..., 237, 60, 12],\n",
              "       [False, False, False, ..., 234, 59, 12],\n",
              "       [False, False, False, ..., 237, 60, 12],\n",
              "       ...,\n",
              "       [True, True, True, ..., 73, 19, 2],\n",
              "       [True, False, False, ..., 100, 25, 2],\n",
              "       [True, True, True, ..., 113, 27, 2]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TabNet"
      ],
      "metadata": {
        "id": "ZKQUDR5XfhOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class F1_Score(Metric):\n",
        "    def __init__(self):\n",
        "        self._name = \"f1\"\n",
        "        self._maximize = True\n",
        "\n",
        "    def __call__(self, y_true, y_score):\n",
        "        score = f1_score(y_true, (y_score[:, 1]>0.5)*1)\n",
        "        return score"
      ],
      "metadata": {
        "id": "HlzwMXJvx3c6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier(cat_idxs=cat_idxs,\n",
        "                       cat_dims=cat_dims,\n",
        "                       cat_emb_dim=3,\n",
        "                       optimizer_fn=torch.optim.AdamW, # Any optimizer works here\n",
        "                       mask_type='entmax', # \"sparsemax\",\n",
        "                      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fOZw3fnffKT",
        "outputId": "b8f89808-27ea-409d-87d0-a3935d8836c0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device used : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    eval_name=['train', 'val'],\n",
        "    eval_metric=['logloss','auc', 'f1'],\n",
        "    max_epochs=100 , patience=2,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=256,\n",
        "    num_workers=1,\n",
        "    drop_last=False,\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw_A2Vzv1dYB",
        "outputId": "30f721eb-051a-498d-e93b-f87aeed0c001"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.68477 | train_logloss: 0.66981 | train_auc: 0.6189  | train_f1: 0.62004 | val_logloss: 0.67018 | val_auc: 0.61717 | val_f1: 0.61787 |  0:00:45s\n",
            "epoch 1  | loss: 0.66666 | train_logloss: 0.65807 | train_auc: 0.6441  | train_f1: 0.6201  | val_logloss: 0.66098 | val_auc: 0.63784 | val_f1: 0.61564 |  0:01:32s\n",
            "epoch 2  | loss: 0.65593 | train_logloss: 0.64619 | train_auc: 0.66558 | train_f1: 0.62613 | val_logloss: 0.6523  | val_auc: 0.65433 | val_f1: 0.61804 |  0:02:20s\n",
            "epoch 3  | loss: 0.6468  | train_logloss: 0.63587 | train_auc: 0.68271 | train_f1: 0.65894 | val_logloss: 0.64663 | val_auc: 0.66552 | val_f1: 0.64478 |  0:03:07s\n",
            "epoch 4  | loss: 0.64049 | train_logloss: 0.63229 | train_auc: 0.69044 | train_f1: 0.66251 | val_logloss: 0.64471 | val_auc: 0.66742 | val_f1: 0.64793 |  0:03:54s\n",
            "epoch 5  | loss: 0.6354  | train_logloss: 0.62395 | train_auc: 0.70143 | train_f1: 0.66331 | val_logloss: 0.6428  | val_auc: 0.67027 | val_f1: 0.64097 |  0:04:40s\n",
            "epoch 6  | loss: 0.6308  | train_logloss: 0.62055 | train_auc: 0.70896 | train_f1: 0.68591 | val_logloss: 0.644   | val_auc: 0.66858 | val_f1: 0.66045 |  0:05:28s\n",
            "epoch 7  | loss: 0.62679 | train_logloss: 0.61564 | train_auc: 0.71517 | train_f1: 0.67435 | val_logloss: 0.6455  | val_auc: 0.66901 | val_f1: 0.64059 |  0:06:15s\n",
            "epoch 8  | loss: 0.62284 | train_logloss: 0.60974 | train_auc: 0.72204 | train_f1: 0.68434 | val_logloss: 0.64592 | val_auc: 0.66605 | val_f1: 0.64565 |  0:07:03s\n",
            "\n",
            "Early stopping occurred at epoch 8 with best_epoch = 6 and best_val_f1 = 0.66045\n",
            "Best weights from best epoch are automatically used!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = clf.predict(X_test)\n",
        "# preds = (preds[:,1]>0.5)*1"
      ],
      "metadata": {
        "id": "WE3D7seV2ceX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "28aa8a4e-199e-4a81-8134-a9c5b91770b1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f93fe7739e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# preds = (preds[:,1]>0.5)*1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# array of string classes and object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp_str_obj_array_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EJrtHvfS7mMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hTz5Q82_7smR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}